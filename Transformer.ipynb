{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Transformer.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1PjWGJ-kaL6eQq9kjVZHPFNYt9rpuilcm","authorship_tag":"ABX9TyMle6k8915C2SromnQfRCs4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6fc33c9174194e25ba054a3be75bd7dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b88a984e834d4848a08753096d9fb94e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ecf04b6a4af14df48234733b10fc943a","IPY_MODEL_227e5e9535d041b1ad2c4f1a8eb35e0e","IPY_MODEL_85212636d56a4182bd3fac32009d7bac"]}},"b88a984e834d4848a08753096d9fb94e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ecf04b6a4af14df48234733b10fc943a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_777ef4c418fe49c59c46d07d660b890a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a7fa102a5c94183bf0029f3d74cdbdc"}},"227e5e9535d041b1ad2c4f1a8eb35e0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34d811a3c6fd4039ba1d9f07154ccc44","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b080690fd5f342469abdd4343f704bbe"}},"85212636d56a4182bd3fac32009d7bac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_76b7ae96606e4f0a9d88f293665c1ed1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.99M/0.99M [00:00&lt;00:00, 1.30MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_454c732d01994b4698d0bcd7ed7abb98"}},"777ef4c418fe49c59c46d07d660b890a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2a7fa102a5c94183bf0029f3d74cdbdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34d811a3c6fd4039ba1d9f07154ccc44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b080690fd5f342469abdd4343f704bbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76b7ae96606e4f0a9d88f293665c1ed1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"454c732d01994b4698d0bcd7ed7abb98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"efffd8ab488c461f8e8e447afa1b642a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4d6c78f227e4407f928220e4a6db4a4a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_535b36c9ba504f93b3b158eec7ad6720","IPY_MODEL_ab7eb4d5342049698abdc2d071c583f7","IPY_MODEL_5e33c370102445fab736a7fcae277c75"]}},"4d6c78f227e4407f928220e4a6db4a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"535b36c9ba504f93b3b158eec7ad6720":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fb372a1ff8e94d8c920ee4d6ebe32bf0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f9408d807614febb2a2b65458969eba"}},"ab7eb4d5342049698abdc2d071c583f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9570a6542a654aff94004026b4920ddd","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d40ca08f5d942579cc7915310261315"}},"5e33c370102445fab736a7fcae277c75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_43ace08f5fce414a942f9b83fca91e5d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 446k/446k [00:00&lt;00:00, 1.41MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53a725de93e340b0bdc8cd0dcdc3030d"}},"fb372a1ff8e94d8c920ee4d6ebe32bf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f9408d807614febb2a2b65458969eba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9570a6542a654aff94004026b4920ddd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0d40ca08f5d942579cc7915310261315":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43ace08f5fce414a942f9b83fca91e5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"53a725de93e340b0bdc8cd0dcdc3030d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d13d0fde462844abb7977e504c44ace3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d5c510e5a5114faea11c268ec4f1b72a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9ea5f71f5f534dd495cc3d8886dea306","IPY_MODEL_7654c3eaaeeb4b8798bd0f1986b408b8","IPY_MODEL_35ae2227a2d0491a8e24add6b1786832"]}},"d5c510e5a5114faea11c268ec4f1b72a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ea5f71f5f534dd495cc3d8886dea306":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_312dea5f0e0e43c293daf8f4adb43c6a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_883ead0435ed48c095083be908356e40"}},"7654c3eaaeeb4b8798bd0f1986b408b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b31c8ccbdee4d51a77c892067df1523","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1197,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1197,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0f7ccb671894748bd3d3e3035c69883"}},"35ae2227a2d0491a8e24add6b1786832":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_74923af72fd0406180ac51831eea6295","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.17k/1.17k [00:00&lt;00:00, 34.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8fac2f3413794fd1bca474540e841096"}},"312dea5f0e0e43c293daf8f4adb43c6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"883ead0435ed48c095083be908356e40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b31c8ccbdee4d51a77c892067df1523":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c0f7ccb671894748bd3d3e3035c69883":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74923af72fd0406180ac51831eea6295":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8fac2f3413794fd1bca474540e841096":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d295a38539a47ed8eadd591d47d82f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_373dc44875f6427f93749a6db8e5f69f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6573469c62eb41b89010d0bcf8268bd3","IPY_MODEL_639a4c6690fa4fa59f090e546517e2f6","IPY_MODEL_2ab3ff9f0eee4841a2c315b6d49dbcf5"]}},"373dc44875f6427f93749a6db8e5f69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6573469c62eb41b89010d0bcf8268bd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d6b124e8e9f4e24af3cc7a1e632045c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a7adabb797c41b198c7ac3e4a8ece7a"}},"639a4c6690fa4fa59f090e546517e2f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5449d20ebfeb466fbe6aed1372996c89","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":791656,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":791656,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9adf6e14f4984eca92a8ae0c3b3d8f88"}},"2ab3ff9f0eee4841a2c315b6d49dbcf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b16e53e1b5cb4c69ace44419ae126688","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 773k/773k [00:00&lt;00:00, 1.72MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7e6eb69400844e6bceffc04c1c27622"}},"3d6b124e8e9f4e24af3cc7a1e632045c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8a7adabb797c41b198c7ac3e4a8ece7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5449d20ebfeb466fbe6aed1372996c89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9adf6e14f4984eca92a8ae0c3b3d8f88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b16e53e1b5cb4c69ace44419ae126688":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7e6eb69400844e6bceffc04c1c27622":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"005cf4c86d40447ca66a83a11228fdab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_30db804e4ed740d3893c887d19a4738a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c37917e987243ca8873c8f1bcb758b5","IPY_MODEL_061d1d137e584e8294dda61f521bbb64","IPY_MODEL_1ae9ca3723884f1d99649880dac49d14"]}},"30db804e4ed740d3893c887d19a4738a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c37917e987243ca8873c8f1bcb758b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_28aa4ed8c1df4fa69ffdbebec23f4ac9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_950d96c265134c21b2526b522c9a30e4"}},"061d1d137e584e8294dda61f521bbb64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90ca46d33cd94800834547d4c7067f5e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1389353,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1389353,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b46234c9c23468b8d0a28b47c873021"}},"1ae9ca3723884f1d99649880dac49d14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69a7a26335674911895ded3384bd5222","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.32M/1.32M [00:00&lt;00:00, 2.88MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43cecf96d2f045548decc93ed8f740a2"}},"28aa4ed8c1df4fa69ffdbebec23f4ac9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"950d96c265134c21b2526b522c9a30e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90ca46d33cd94800834547d4c7067f5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2b46234c9c23468b8d0a28b47c873021":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69a7a26335674911895ded3384bd5222":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"43cecf96d2f045548decc93ed8f740a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71ff1f0ea21645db8426cb0f4e7c53a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3383e610d2854b5585b9fac35dd6c952","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6678918673af4099a6a5266f6252313f","IPY_MODEL_df7a42d381c84091ac44c0ac66648f79","IPY_MODEL_344847a36a7c46a795ac5334a41fb878"]}},"3383e610d2854b5585b9fac35dd6c952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6678918673af4099a6a5266f6252313f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c7f38355e534901b26f9f57e6aee76b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a3384b47c7b34baaa73d968ca2dd333f"}},"df7a42d381c84091ac44c0ac66648f79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b07922a9a2194346aa5e201c3a58f5be","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":242065649,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":242065649,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e27541789708494db00a461902823ee0"}},"344847a36a7c46a795ac5334a41fb878":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5daa78f5d5342e180ecd46538612d49","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 231M/231M [00:04&lt;00:00, 52.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9cb1e7384c84459a95f6ec101c7f5711"}},"4c7f38355e534901b26f9f57e6aee76b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a3384b47c7b34baaa73d968ca2dd333f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b07922a9a2194346aa5e201c3a58f5be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e27541789708494db00a461902823ee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5daa78f5d5342e180ecd46538612d49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9cb1e7384c84459a95f6ec101c7f5711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a789d7a111d408ca1f472c77087e07f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fef02b43cb254429a73eeb179dd1516d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fe227e468a4c476483451f16f07470e2","IPY_MODEL_1c2f55aaf44f499aaff05df02f2b40c7","IPY_MODEL_8184daf50d5f4676a99c9bedfbb10fda"]}},"fef02b43cb254429a73eeb179dd1516d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe227e468a4c476483451f16f07470e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6cf72fdcea80442987ab7586691a0296","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e29d04321061444faa16902b5a2abf1a"}},"1c2f55aaf44f499aaff05df02f2b40c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8ee8d4dacc0b4288986cb4239ff0b4ad","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2170,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2170,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_395fda2b11554c45884496342de51d23"}},"8184daf50d5f4676a99c9bedfbb10fda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cd561c7d4a1c400e8694649ea8a38e4f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.61k/? [00:00&lt;00:00, 212kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9950ec818ac74b7c92554290cf984a35"}},"6cf72fdcea80442987ab7586691a0296":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e29d04321061444faa16902b5a2abf1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ee8d4dacc0b4288986cb4239ff0b4ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"395fda2b11554c45884496342de51d23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd561c7d4a1c400e8694649ea8a38e4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9950ec818ac74b7c92554290cf984a35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEgyD3nfR-vo","executionInfo":{"status":"ok","timestamp":1637178415961,"user_tz":-480,"elapsed":354,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"b565080a-a1e4-49ce-a288-12ec875c5b37"},"source":["cd /content/drive/MyDrive/20210611任务"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/20210611任务\n"]}]},{"cell_type":"code","metadata":{"id":"tXqvgfY5LFMx"},"source":["!pip install transformers sentencepiece datasets rouge_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLXzsMu6D86w"},"source":["初步设想建立语义关系三元组（Q S A）\n","Q：问题\n","S：含义\n","A：答案文本\n","\n","A方案：\n","1.   利用Bert对医学样本建立词向量库\n","2.   使用Transformer对A进行S提取\n","3.   对比Q与S库的欧式距离，从而选出答案\n","\n","\n","B方案：\n","1.   利用Bert对医学样本建立词向量库\n","2.   使用GPT2增强Q样本\n","3.   Transformer对A进行S1提取\n","4.   Transformer对Q进行S2提取\n","5.   对比S1与S2的欧式距离，从而选出答案"]},{"cell_type":"code","metadata":{"id":"wwRtAxmvEVci","executionInfo":{"status":"ok","timestamp":1637178470794,"user_tz":-480,"elapsed":1897,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}}},"source":["import numpy as np\n","import pandas as pd\n","from pathlib import Path \n","\n","import os\n","\n","import torch\n","import torch.optim as optim\n","\n","import random \n","from fastai import *\n","from fastai.text import *\n","from fastai.callbacks import *\n","from transformers import AdamW\n","from functools import partial"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3T8lPgKNYqbv","executionInfo":{"status":"ok","timestamp":1637178476898,"user_tz":-480,"elapsed":1898,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}}},"source":["from sklearn.model_selection import train_test_split\n","f = open('./diseaseBERT/diseaseKnowledgeInfusionTraining/data/extractedQuestionAnswers_total_removeNoisy_maskedLM.txt','r')\n","total_text = f.read().split('\\n')[:-1]\n","\n","total_train,total_test,_,_ = train_test_split(total_text,[0 for line in total_text],test_size=0.2,random_state=66)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2jomh30Yrku","executionInfo":{"status":"ok","timestamp":1637178478318,"user_tz":-480,"elapsed":2,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}}},"source":["S_train_dic = {}\n","Q_train_dic = {}\n","A_train_dic = {}\n","for key, line in enumerate(total_train):\n","  SQA_temp = line.split('?\\t')\n","  SQ_temp = SQA_temp[0].split('\\t')\n","  S_train_dic[key] = SQ_temp[0] + ' : ' + SQ_temp[1]\n","  Q_train_dic[key] = SQ_temp[2]\n","  A_train_dic[key] = SQA_temp[1]\n","\n","S_test_dic = {}\n","Q_test_dic = {}\n","A_test_dic = {}\n","for key, line in enumerate(total_test):\n","  SQA_temp = line.split('?\\t')\n","  SQ_temp = SQA_temp[0].split('\\t')\n","  S_test_dic[key] = SQ_temp[0] + ' : ' + SQ_temp[1]\n","  Q_test_dic[key] = SQ_temp[2]\n","  A_test_dic[key] = SQA_temp[1]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUgviwxCRcKm","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1637178481171,"user_tz":-480,"elapsed":356,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"66b4ea2f-d28b-423a-f96a-d2402d70210c"},"source":["import pandas as pd\n","\n","data = pd.DataFrame({'S':list(S_train_dic.values()),'Q':list(Q_train_dic.values()),'A':list(A_train_dic.values())})\n","data"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>S</th>\n","      <th>Q</th>\n","      <th>A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>gangrene : treatments</td>\n","      <td>what are the treatments of gangrene</td>\n","      <td>treatment varies based on the severity and typ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>multiple endocrine neoplasia type 1 : treatments</td>\n","      <td>what are the treatments of multiple endocrine ...</td>\n","      <td>the treatment of choice of parathyroid tumors ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>pancreatic pseudocyst : diagnosis</td>\n","      <td>what are the diagnosis of pancreatic pseudocyst</td>\n","      <td>diagnosis of pancreatic pseudocyst can be base...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>oral submucous fibrosis : physiology</td>\n","      <td>what are the physiology of oral submucous fibr...</td>\n","      <td>\"exposure to areca nut (arecacatechu) containi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>thrombophilia : diagnosis</td>\n","      <td>what are the diagnosis of thrombophilia</td>\n","      <td>tests for thrombophilia include complete blood...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11688</th>\n","      <td>behçet's disease : treatments</td>\n","      <td>what are the treatments of behçet's disease</td>\n","      <td>current treatment is aimed at easing the sympt...</td>\n","    </tr>\n","    <tr>\n","      <th>11689</th>\n","      <td>tetany : general</td>\n","      <td>what is tetany</td>\n","      <td>tetany or tetanic seizure is a medical sign co...</td>\n","    </tr>\n","    <tr>\n","      <th>11690</th>\n","      <td>avulsion fracture : treatments</td>\n","      <td>what are the treatments of avulsion fracture</td>\n","      <td>if the fracture is small, it is usually suffic...</td>\n","    </tr>\n","    <tr>\n","      <th>11691</th>\n","      <td>lichen planus : treatments</td>\n","      <td>what are the treatments of lichen planus</td>\n","      <td>there is no cure for lichen planus, when medic...</td>\n","    </tr>\n","    <tr>\n","      <th>11692</th>\n","      <td>wound : diagnosis</td>\n","      <td>what are the diagnosis of wound</td>\n","      <td>a wound may be recorded for follow-up and obse...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11693 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                      S  ...                                                  A\n","0                                 gangrene : treatments  ...  treatment varies based on the severity and typ...\n","1      multiple endocrine neoplasia type 1 : treatments  ...  the treatment of choice of parathyroid tumors ...\n","2                     pancreatic pseudocyst : diagnosis  ...  diagnosis of pancreatic pseudocyst can be base...\n","3                  oral submucous fibrosis : physiology  ...  \"exposure to areca nut (arecacatechu) containi...\n","4                             thrombophilia : diagnosis  ...  tests for thrombophilia include complete blood...\n","...                                                 ...  ...                                                ...\n","11688                     behçet's disease : treatments  ...  current treatment is aimed at easing the sympt...\n","11689                                  tetany : general  ...  tetany or tetanic seizure is a medical sign co...\n","11690                    avulsion fracture : treatments  ...  if the fracture is small, it is usually suffic...\n","11691                        lichen planus : treatments  ...  there is no cure for lichen planus, when medic...\n","11692                                 wound : diagnosis  ...  a wound may be recorded for follow-up and obse...\n","\n","[11693 rows x 3 columns]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"brrqHCBBcxx7"},"source":["# GPT2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["6fc33c9174194e25ba054a3be75bd7dc","b88a984e834d4848a08753096d9fb94e","ecf04b6a4af14df48234733b10fc943a","227e5e9535d041b1ad2c4f1a8eb35e0e","85212636d56a4182bd3fac32009d7bac","777ef4c418fe49c59c46d07d660b890a","2a7fa102a5c94183bf0029f3d74cdbdc","34d811a3c6fd4039ba1d9f07154ccc44","b080690fd5f342469abdd4343f704bbe","76b7ae96606e4f0a9d88f293665c1ed1","454c732d01994b4698d0bcd7ed7abb98","efffd8ab488c461f8e8e447afa1b642a","4d6c78f227e4407f928220e4a6db4a4a","535b36c9ba504f93b3b158eec7ad6720","ab7eb4d5342049698abdc2d071c583f7","5e33c370102445fab736a7fcae277c75","fb372a1ff8e94d8c920ee4d6ebe32bf0","7f9408d807614febb2a2b65458969eba","9570a6542a654aff94004026b4920ddd","0d40ca08f5d942579cc7915310261315","43ace08f5fce414a942f9b83fca91e5d","53a725de93e340b0bdc8cd0dcdc3030d"]},"id":"Vl_1fWqRcxUd","executionInfo":{"status":"ok","timestamp":1637178941468,"user_tz":-480,"elapsed":3532,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"00d01620-e7f8-4d11-c28e-44367a0c5e54"},"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextGenerationPipeline\n","\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fc33c9174194e25ba054a3be75bd7dc","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efffd8ab488c461f8e8e447afa1b642a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"JsvMzkRcfTSF","executionInfo":{"status":"ok","timestamp":1637178489925,"user_tz":-480,"elapsed":338,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}}},"source":["QStrain_data = []\n","QStest_data = []\n","\n","for indexs in range(len(list(Q_train_dic.values()))):\n","  QStrain_data.append([Q_train_dic[indexs],S_train_dic[indexs]])\n","for indexs in range(len(list(Q_test_dic.values()))):\n","  QStest_data.append([Q_test_dic[indexs],S_test_dic[indexs]])\n","\n","AStrain_data = []\n","AStest_data = []\n","\n","for indexs in range(len(list(A_train_dic.values()))):\n","  AStrain_data.append([A_train_dic[indexs],S_train_dic[indexs]])\n","for indexs in range(len(list(A_test_dic.values()))):\n","  AStest_data.append([A_test_dic[indexs],S_test_dic[indexs]])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"DlNKcmIii92E","executionInfo":{"status":"ok","timestamp":1637180691941,"user_tz":-480,"elapsed":337,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}}},"source":["from tqdm.auto import tqdm\n","from transformers import pipeline, set_seed\n","generator = pipeline('text-generation', model='gpt2')\n","set_seed(4)\n","all_data = []\n","for line in tqdm(QStrain_data):\n","  qTemp = line[0].split(\" \")\n","  qTemp = generator(\" \".join(qTemp[:len(qTemp)//3 * 2]), max_length=16, num_return_sequences=10)\n","  for dic in qTemp:\n","    all_data.append([dic['generated_text'].replace(\"\\n\",\"\"), line[1]])\n","QStrain_data = all_data"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDdBdSsHNxia","colab":{"base_uri":"https://localhost:8080/","height":180,"referenced_widgets":["d13d0fde462844abb7977e504c44ace3","d5c510e5a5114faea11c268ec4f1b72a","9ea5f71f5f534dd495cc3d8886dea306","7654c3eaaeeb4b8798bd0f1986b408b8","35ae2227a2d0491a8e24add6b1786832","312dea5f0e0e43c293daf8f4adb43c6a","883ead0435ed48c095083be908356e40","3b31c8ccbdee4d51a77c892067df1523","c0f7ccb671894748bd3d3e3035c69883","74923af72fd0406180ac51831eea6295","8fac2f3413794fd1bca474540e841096","5d295a38539a47ed8eadd591d47d82f0","373dc44875f6427f93749a6db8e5f69f","6573469c62eb41b89010d0bcf8268bd3","639a4c6690fa4fa59f090e546517e2f6","2ab3ff9f0eee4841a2c315b6d49dbcf5","3d6b124e8e9f4e24af3cc7a1e632045c","8a7adabb797c41b198c7ac3e4a8ece7a","5449d20ebfeb466fbe6aed1372996c89","9adf6e14f4984eca92a8ae0c3b3d8f88","b16e53e1b5cb4c69ace44419ae126688","a7e6eb69400844e6bceffc04c1c27622","005cf4c86d40447ca66a83a11228fdab","30db804e4ed740d3893c887d19a4738a","9c37917e987243ca8873c8f1bcb758b5","061d1d137e584e8294dda61f521bbb64","1ae9ca3723884f1d99649880dac49d14","28aa4ed8c1df4fa69ffdbebec23f4ac9","950d96c265134c21b2526b522c9a30e4","90ca46d33cd94800834547d4c7067f5e","2b46234c9c23468b8d0a28b47c873021","69a7a26335674911895ded3384bd5222","43cecf96d2f045548decc93ed8f740a2","71ff1f0ea21645db8426cb0f4e7c53a7","3383e610d2854b5585b9fac35dd6c952","6678918673af4099a6a5266f6252313f","df7a42d381c84091ac44c0ac66648f79","344847a36a7c46a795ac5334a41fb878","4c7f38355e534901b26f9f57e6aee76b","a3384b47c7b34baaa73d968ca2dd333f","b07922a9a2194346aa5e201c3a58f5be","e27541789708494db00a461902823ee0","f5daa78f5d5342e180ecd46538612d49","9cb1e7384c84459a95f6ec101c7f5711"]},"executionInfo":{"status":"ok","timestamp":1633116957878,"user_tz":-480,"elapsed":22445,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"596926eb-3a31-49aa-839f-9d63391ae10b"},"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,Seq2SeqTrainingArguments\n","# model_name = \"google/roberta2roberta_L-24_cnn_daily_mail\"\n","model_name = \"t5-small\"\n","# model_name = '/content/drive/MyDrive/20210611任务/AS-summarization/checkpoint-2000'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","Qtrain_encoding = tokenizer(\n","    list(Q_train_dic.values()),\n","    padding=True,\n","    truncation=True,\n","    max_length=16,\n","    return_tensors=\"pt\"\n",")\n","\n","Strain_label_encoding = tokenizer(\n","    list(S_train_dic.values()),\n","    padding=True,\n","    truncation=True,\n","    max_length=16,\n","    return_tensors=\"pt\"\n",")\n","\n","Qtest_encoding = tokenizer(\n","    list(Q_test_dic.values()),\n","    padding=True,\n","    truncation=True,\n","    max_length=16,\n","    return_tensors=\"pt\"\n",")\n","\n","Stest_label_encoding = tokenizer(\n","    list(S_test_dic.values()),\n","    padding=True,\n","    truncation=True,\n","    max_length=16,\n","    return_tensors=\"pt\"\n",")\n","\n","\n","Atrain_encoding = tokenizer(\n","    list(A_train_dic.values()),\n","    padding=True,\n","    truncation=True,\n","    max_length=256,\n","    return_tensors=\"pt\"\n",")\n","\n","Atest_encoding = tokenizer(\n","    list(A_test_dic.values()),\n","    padding=True,\n","    truncation=True,\n","    max_length=256,\n","    return_tensors=\"pt\"\n",")\n","\n","# A_batch = tokenizer(\n","#     list(A_dic.values()),\n","#     padding=True,\n","#     truncation=True,\n","#     max_length=512,\n","#     return_tensors=\"pt\"\n","# )"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d13d0fde462844abb7977e504c44ace3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d295a38539a47ed8eadd591d47d82f0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"005cf4c86d40447ca66a83a11228fdab","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71ff1f0ea21645db8426cb0f4e7c53a7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n","  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"]}]},{"cell_type":"code","metadata":{"id":"AJIN_kisuTXJ"},"source":["class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n"," \n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n"," \n","    def __len__(self):\n","        return len(self.labels)\n"," \n","QStrain_dataset = IMDbDataset(Qtrain_encoding, Strain_label_encoding['input_ids'])\n","QStest_dataset = IMDbDataset(Qtest_encoding, Stest_label_encoding['input_ids'])\n","\n","AStrain_dataset = IMDbDataset(Atrain_encoding, Strain_label_encoding['input_ids'])\n","AStest_dataset = IMDbDataset(Atest_encoding, Stest_label_encoding['input_ids'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLX-AivQ154d","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["0a789d7a111d408ca1f472c77087e07f","fef02b43cb254429a73eeb179dd1516d","fe227e468a4c476483451f16f07470e2","1c2f55aaf44f499aaff05df02f2b40c7","8184daf50d5f4676a99c9bedfbb10fda","6cf72fdcea80442987ab7586691a0296","e29d04321061444faa16902b5a2abf1a","8ee8d4dacc0b4288986cb4239ff0b4ad","395fda2b11554c45884496342de51d23","cd561c7d4a1c400e8694649ea8a38e4f","9950ec818ac74b7c92554290cf984a35"]},"executionInfo":{"status":"ok","timestamp":1633116960610,"user_tz":-480,"elapsed":2748,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"782525f8-a2f9-4d9c-8250-ac8d2ed3e292"},"source":["import nltk\n","import numpy as np\n","from datasets import load_metric\n","nltk.download('punkt')\n","metric = load_metric(\"rouge\")\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    \n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a789d7a111d408ca1f472c77087e07f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"OHMFKzTHhlTT","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1633117126066,"user_tz":-480,"elapsed":165462,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"3b65a5f8-6ed8-430a-eb9e-340848b320bb"},"source":["#QS\n","from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer\n","training_args = Seq2SeqTrainingArguments(\n","    \"QS-summarization\",\n","    evaluation_strategy = \"epoch\",\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=32,  # batch size per device during training\n","    per_device_eval_batch_size=32,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.001,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n","    predict_with_generate=True,\n","    fp16=True,\n",")\n","# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    training_args,\n","    train_dataset=QStrain_dataset,\n","    eval_dataset=QStest_dataset,\n","    # data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using amp fp16 backend\n","***** Running training *****\n","  Num examples = 11693\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1098\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1098' max='1098' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1098/1098 02:38, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.089500</td>\n","      <td>0.070495</td>\n","      <td>97.893800</td>\n","      <td>95.936800</td>\n","      <td>97.868600</td>\n","      <td>97.859600</td>\n","      <td>9.826900</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.070200</td>\n","      <td>0.040085</td>\n","      <td>98.178400</td>\n","      <td>96.655700</td>\n","      <td>98.185900</td>\n","      <td>98.180800</td>\n","      <td>9.861100</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.027600</td>\n","      <td>0.036042</td>\n","      <td>98.212200</td>\n","      <td>96.704500</td>\n","      <td>98.217000</td>\n","      <td>98.210900</td>\n","      <td>9.868300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2924\n","  Batch size = 32\n","Saving model checkpoint to QS-summarization/checkpoint-500\n","Configuration saved in QS-summarization/checkpoint-500/config.json\n","Model weights saved in QS-summarization/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in QS-summarization/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in QS-summarization/checkpoint-500/special_tokens_map.json\n","Copy vocab file to QS-summarization/checkpoint-500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 2924\n","  Batch size = 32\n","Saving model checkpoint to QS-summarization/checkpoint-1000\n","Configuration saved in QS-summarization/checkpoint-1000/config.json\n","Model weights saved in QS-summarization/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in QS-summarization/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in QS-summarization/checkpoint-1000/special_tokens_map.json\n","Copy vocab file to QS-summarization/checkpoint-1000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 2924\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1098, training_loss=0.8429933545096542, metrics={'train_runtime': 158.5054, 'train_samples_per_second': 221.311, 'train_steps_per_second': 6.927, 'total_flos': 148364220432384.0, 'train_loss': 0.8429933545096542, 'epoch': 3.0})"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"M7B9CHPsNbAR","executionInfo":{"status":"ok","timestamp":1633118988755,"user_tz":-480,"elapsed":149976,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"be8275fc-4320-49f7-a6ab-f83b39a8c76a"},"source":["training_args = Seq2SeqTrainingArguments(\n","    \"QS-summarization\",\n","    evaluation_strategy = \"epoch\",\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=32,  # batch size per device during training\n","    per_device_eval_batch_size=32,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n","    predict_with_generate=True,\n","    fp16=True,\n",")\n","# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    training_args,\n","    train_dataset=QStrain_dataset,\n","    eval_dataset=QStest_dataset,\n","    # data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","Using amp fp16 backend\n","***** Running training *****\n","  Num examples = 11693\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1098\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1098' max='1098' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1098/1098 02:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.025300</td>\n","      <td>0.028251</td>\n","      <td>98.450500</td>\n","      <td>97.241300</td>\n","      <td>98.447300</td>\n","      <td>98.446900</td>\n","      <td>9.885400</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.035800</td>\n","      <td>0.022288</td>\n","      <td>98.631100</td>\n","      <td>97.530700</td>\n","      <td>98.635200</td>\n","      <td>98.623700</td>\n","      <td>9.888900</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.013600</td>\n","      <td>0.021125</td>\n","      <td>98.678600</td>\n","      <td>97.660300</td>\n","      <td>98.681100</td>\n","      <td>98.668200</td>\n","      <td>9.893000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","***** Running Evaluation *****\n","  Num examples = 2924\n","  Batch size = 32\n","Saving model checkpoint to QS-summarization/checkpoint-500\n","Configuration saved in QS-summarization/checkpoint-500/config.json\n","Model weights saved in QS-summarization/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in QS-summarization/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in QS-summarization/checkpoint-500/special_tokens_map.json\n","Copy vocab file to QS-summarization/checkpoint-500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 2924\n","  Batch size = 32\n","Saving model checkpoint to QS-summarization/checkpoint-1000\n","Configuration saved in QS-summarization/checkpoint-1000/config.json\n","Model weights saved in QS-summarization/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in QS-summarization/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in QS-summarization/checkpoint-1000/special_tokens_map.json\n","Copy vocab file to QS-summarization/checkpoint-1000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 2924\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1098, training_loss=0.0329151949310889, metrics={'train_runtime': 149.6737, 'train_samples_per_second': 234.37, 'train_steps_per_second': 7.336, 'total_flos': 148364220432384.0, 'train_loss': 0.0329151949310889, 'epoch': 3.0})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"id":"lpnb6GWQOqF5","executionInfo":{"status":"error","timestamp":1633114851346,"user_tz":-480,"elapsed":438,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"9464f333-6b2e-4cf5-de0d-6ba3efb0ffcf"},"source":["training_args = Seq2SeqTrainingArguments(\n","    \"QS-summarization\",\n","    evaluation_strategy = \"epoch\",\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n","    predict_with_generate=True,\n","    fp16=True,\n",")\n","# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    training_args,\n","    train_dataset=QStrain_dataset,\n","    eval_dataset=QStest_dataset,\n","    # data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","Using amp fp16 backend\n","***** Running training *****\n","  Num examples = 11693\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2193\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-19b7379f06ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1578\u001b[0;31m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m             )\n\u001b[1;32m   1580\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You have to initialize the model with valid token embeddings\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 14.87 GiB already allocated; 21.75 MiB free; 14.97 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"j2kSLVtcAN9i"},"source":["features_in_hook = []\n","features_out_hook = []\n","\n","def hook(module, fea_in, fea_out):\n","    features_in_hook.append(fea_in)\n","    features_out_hook.append(fea_out)\n","    return None\n","\n","layer_name = 'decoder'\n","for (name, module) in model.named_modules():\n","    if name == layer_name:\n","        module.register_forward_hook(hook=hook)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OdwtE9J7xh7a","executionInfo":{"status":"error","timestamp":1633118832946,"user_tz":-480,"elapsed":1706903,"user":{"displayName":"jonney wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03399868621473431933"}},"outputId":"c85cd608-4f45-42ce-9845-4e2ab59752d1"},"source":["#AS\n","from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer\n","training_args = Seq2SeqTrainingArguments(\n","    \"AS-summarization\",\n","    evaluation_strategy = \"epoch\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    predict_with_generate=True,\n","    fp16=True,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    training_args,\n","    train_dataset=AStrain_dataset,\n","    eval_dataset=AStest_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","Using amp fp16 backend\n","***** Running training *****\n","  Num examples = 11693\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 35079\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='20693' max='35079' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [20693/35079 28:26 < 19:46, 12.12 it/s, Epoch 1.77/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.650500</td>\n","      <td>0.493238</td>\n","      <td>74.885200</td>\n","      <td>62.177600</td>\n","      <td>74.792600</td>\n","      <td>74.872800</td>\n","      <td>9.326600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to AS-summarization/checkpoint-500\n","Configuration saved in AS-summarization/checkpoint-500/config.json\n","Model weights saved in AS-summarization/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-1000\n","Configuration saved in AS-summarization/checkpoint-1000/config.json\n","Model weights saved in AS-summarization/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-1000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-1000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-1500\n","Configuration saved in AS-summarization/checkpoint-1500/config.json\n","Model weights saved in AS-summarization/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-1500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-1500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-2000\n","Configuration saved in AS-summarization/checkpoint-2000/config.json\n","Model weights saved in AS-summarization/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-2000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-2000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-2500\n","Configuration saved in AS-summarization/checkpoint-2500/config.json\n","Model weights saved in AS-summarization/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-2500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-2500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-3000\n","Configuration saved in AS-summarization/checkpoint-3000/config.json\n","Model weights saved in AS-summarization/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-3000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-3000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-3500\n","Configuration saved in AS-summarization/checkpoint-3500/config.json\n","Model weights saved in AS-summarization/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-3500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-3500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-4000\n","Configuration saved in AS-summarization/checkpoint-4000/config.json\n","Model weights saved in AS-summarization/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-4000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-4000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-4500\n","Configuration saved in AS-summarization/checkpoint-4500/config.json\n","Model weights saved in AS-summarization/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-4500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-4500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-5000\n","Configuration saved in AS-summarization/checkpoint-5000/config.json\n","Model weights saved in AS-summarization/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-5000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-5000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-5500\n","Configuration saved in AS-summarization/checkpoint-5500/config.json\n","Model weights saved in AS-summarization/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-5500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-5500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-6000\n","Configuration saved in AS-summarization/checkpoint-6000/config.json\n","Model weights saved in AS-summarization/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-6000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-6000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-6500\n","Configuration saved in AS-summarization/checkpoint-6500/config.json\n","Model weights saved in AS-summarization/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-6500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-6500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-7000\n","Configuration saved in AS-summarization/checkpoint-7000/config.json\n","Model weights saved in AS-summarization/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-7000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-7000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-7500\n","Configuration saved in AS-summarization/checkpoint-7500/config.json\n","Model weights saved in AS-summarization/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-7500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-7500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-8000\n","Configuration saved in AS-summarization/checkpoint-8000/config.json\n","Model weights saved in AS-summarization/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-8000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-8000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-8500\n","Configuration saved in AS-summarization/checkpoint-8500/config.json\n","Model weights saved in AS-summarization/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-8500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-8500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-9000\n","Configuration saved in AS-summarization/checkpoint-9000/config.json\n","Model weights saved in AS-summarization/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-9000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-9000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-9500\n","Configuration saved in AS-summarization/checkpoint-9500/config.json\n","Model weights saved in AS-summarization/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-9500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-9500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-10000\n","Configuration saved in AS-summarization/checkpoint-10000/config.json\n","Model weights saved in AS-summarization/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-10000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-10000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-10500\n","Configuration saved in AS-summarization/checkpoint-10500/config.json\n","Model weights saved in AS-summarization/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-10500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-10500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-11000\n","Configuration saved in AS-summarization/checkpoint-11000/config.json\n","Model weights saved in AS-summarization/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-11000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-11000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-11500\n","Configuration saved in AS-summarization/checkpoint-11500/config.json\n","Model weights saved in AS-summarization/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-11500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-11500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 2924\n","  Batch size = 1\n","Saving model checkpoint to AS-summarization/checkpoint-12000\n","Configuration saved in AS-summarization/checkpoint-12000/config.json\n","Model weights saved in AS-summarization/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-12000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-12000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-12500\n","Configuration saved in AS-summarization/checkpoint-12500/config.json\n","Model weights saved in AS-summarization/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-12500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-12500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-13000\n","Configuration saved in AS-summarization/checkpoint-13000/config.json\n","Model weights saved in AS-summarization/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-13000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-13000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-13500\n","Configuration saved in AS-summarization/checkpoint-13500/config.json\n","Model weights saved in AS-summarization/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-13500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-13500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-14000\n","Configuration saved in AS-summarization/checkpoint-14000/config.json\n","Model weights saved in AS-summarization/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-14000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-14000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-14500\n","Configuration saved in AS-summarization/checkpoint-14500/config.json\n","Model weights saved in AS-summarization/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-14500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-14500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-15000\n","Configuration saved in AS-summarization/checkpoint-15000/config.json\n","Model weights saved in AS-summarization/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-15000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-15000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-15500\n","Configuration saved in AS-summarization/checkpoint-15500/config.json\n","Model weights saved in AS-summarization/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-15500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-15500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-16000\n","Configuration saved in AS-summarization/checkpoint-16000/config.json\n","Model weights saved in AS-summarization/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-16000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-16000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-16500\n","Configuration saved in AS-summarization/checkpoint-16500/config.json\n","Model weights saved in AS-summarization/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-16500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-16500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-17000\n","Configuration saved in AS-summarization/checkpoint-17000/config.json\n","Model weights saved in AS-summarization/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-17000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-17000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-17500\n","Configuration saved in AS-summarization/checkpoint-17500/config.json\n","Model weights saved in AS-summarization/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-17500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-17500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-18000\n","Configuration saved in AS-summarization/checkpoint-18000/config.json\n","Model weights saved in AS-summarization/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-18000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-18000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-18500\n","Configuration saved in AS-summarization/checkpoint-18500/config.json\n","Model weights saved in AS-summarization/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-18500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-18500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-19000\n","Configuration saved in AS-summarization/checkpoint-19000/config.json\n","Model weights saved in AS-summarization/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-19000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-19000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1349: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to AS-summarization/checkpoint-19500\n","Configuration saved in AS-summarization/checkpoint-19500/config.json\n","Model weights saved in AS-summarization/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-19500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-19500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-20000\n","Configuration saved in AS-summarization/checkpoint-20000/config.json\n","Model weights saved in AS-summarization/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-20000/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-20000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","Saving model checkpoint to AS-summarization/checkpoint-20500\n","Configuration saved in AS-summarization/checkpoint-20500/config.json\n","Model weights saved in AS-summarization/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in AS-summarization/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in AS-summarization/checkpoint-20500/special_tokens_map.json\n","Copy vocab file to AS-summarization/checkpoint-20500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-9690d4eba95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"n_HXga6r9Hwq"},"source":["from transformers import pipeline\n","# model.device('cpu')\n","processor = pipeline('summarization', tokenizer=tokenizer, model=model.cpu())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCUWY53OzZ-K"},"source":["result = []\n","\n","for i in tqdm(range(len(Qtest_encoding[\"input_ids\"])))\n","  model.generate(Qtest_encoding[\"input_ids\"][i:i+1].cuda(), do_sample=True, num_return_sequences=1, output_scores=True)\n","  result.append(features_out_hook[0]['last_hidden_state'])\n","  features_out_hook = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A76q_u8HCcGg"},"source":["pd.DataFrame({\"Prediction\":result}).to_csv(\"Q2S.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lkRbNZTI68Y"},"source":[""],"execution_count":null,"outputs":[]}]}